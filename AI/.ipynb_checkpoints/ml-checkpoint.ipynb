{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6-S2CxoVZKk"
   },
   "source": [
    "# Import libraray and Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "INAVooq1vOdj"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ycCpFpcV3IZ"
   },
   "source": [
    "# Prepare X, y for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvcPfdWevx6L"
   },
   "outputs": [],
   "source": [
    "# count the number of data in each layer\n",
    "# 0(mono), 1(bi), 2(tri), 3(quad), 4(penta), 5(thick)\n",
    "def calculate_feature_lengths(df, index):\n",
    "  lengths = {}\n",
    "  for i in index:\n",
    "    lengths[i] = len(df['data'][0][i]['dist']['RGB_dist'])\n",
    "  return lengths\n",
    "\n",
    "# configure X for machine learning\n",
    "def make_X(df, indices):\n",
    "    data_list = []\n",
    "    for index in indices:\n",
    "        data = df['data'][0][index]['dist']\n",
    "        X_data = []\n",
    "        for key, value in data.items():\n",
    "            X_data.append(np.array(value))\n",
    "        data_list.append(np.column_stack(X_data).T)\n",
    "\n",
    "    return np.concatenate(data_list, axis=1)\n",
    "\n",
    "# configure y for machine learning\n",
    "def make_Y(index_feature_lengths):\n",
    "  y = []\n",
    "  for key, value in index_feature_lengths.items():\n",
    "    for _ in range(value):\n",
    "      y.append(key)\n",
    "  return np.array(y).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file_path = os.getcwd()\n",
    "current_dir = os.path.dirname(current_file_path)\n",
    "input_file_path = os.path.join(current_dir, \"data_preprocess\", \"data\", \"json\", \"Graphene_merge.json\")\n",
    "output_file_dir = os.path.join(current_dir, \"AI\", \"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YG13i1h7uXmw",
    "outputId": "e68e5ce0-7ddd-4a34-b1a7-456e65f03df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "material:Graphene\n",
      "substrate:Gelpack\n",
      "{0: 8633, 1: 2272, 2: 650, 3: 0, 4: 0, 5: 4975}\n"
     ]
    }
   ],
   "source": [
    "# Load data (material, color for confusion matrix)\n",
    "material_and_color = [('Graphene', 'Blues')]\n",
    "idx = 0\n",
    "\n",
    "with open(input_file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# JSON -> Pandas DataFrame\n",
    "df = pd.json_normalize(json_data)\n",
    "\n",
    "# Load material and substrate data\n",
    "MATERIAL = df['material'].to_string(index=False)\n",
    "SUBSTRATE = df['substrate'].to_string(index=False)\n",
    "COLOR = material_and_color[idx][1]\n",
    "print(f'material:{MATERIAL}\\nsubstrate:{SUBSTRATE}')\n",
    "\n",
    "# Load layer data in material\n",
    "index = [0, 1, 2, 3, 4, 5] # mono, bi, tri, quad, penta, thick\n",
    "index_feature_lengths = calculate_feature_lengths(df, index) # count the data according to the number of layer\n",
    "print(index_feature_lengths)\n",
    "\n",
    "# make X, y\n",
    "data_labels = [key for key, item in index_feature_lengths.items() if item > 0]\n",
    "y = make_Y(index_feature_lengths)\n",
    "X = make_X(df, index)\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIJJzD6ywLyK"
   },
   "source": [
    "# Multiple Classifcation\n",
    "\n",
    "v1. train vs valid vs test & valid, test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "90Awfb2DluNT"
   },
   "outputs": [],
   "source": [
    "def machineLearning_print_val_test(feature, X=X, y=y, material=MATERIAL, color=COLOR, labels=data_labels):\n",
    "\n",
    "    # merge confusion matrices in one image file\n",
    "    def combine_images(images):\n",
    "        images = [Image.open(x) for x in images]\n",
    "        widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "        total_width = sum(widths)\n",
    "        max_height = max(heights)\n",
    "\n",
    "        combined_image = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "        x_offset = 0\n",
    "\n",
    "        for im in images:\n",
    "            combined_image.paste(im, (x_offset, 0))\n",
    "            x_offset += im.size[0]\n",
    "\n",
    "        return combined_image\n",
    "\n",
    "    feature_mapping = {\n",
    "        'rgb': 'RGB', 'yiq': 'YIQ'\n",
    "    }\n",
    "\n",
    "    feature_names = [feature_mapping.get(f, f.upper()) for f in feature]\n",
    "    feature_name = ''.join(feature_names)\n",
    "    \n",
    "    output_file_path_for_conf_mat = os.path.join(output_file_dir, feature_name, \".png\")\n",
    "    output_file_path_for_table = os.path.join(output_file_dir, feature_name, \".csv\")\n",
    "\n",
    "    feature_dict = {\n",
    "        'RGB_dist': 0, 'YIQ_dist': 1\n",
    "    }\n",
    "\n",
    "    feature_indices = [feature_dict[f] for f in feature]\n",
    "    X_selected = X[:, feature_indices]\n",
    "\n",
    "    # Train/Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    layer_dict = {0: 'mono', 1: 'bi', 2:'tri', 3:'quad', 4: 'penta', 5: 'thick'}\n",
    "    layer_labels = [layer_dict[lb] for lb in labels]\n",
    "    layer_numbers = [key for key, value in layer_dict.items() if value in layer_labels]\n",
    "\n",
    "    fold_results_list = []\n",
    "    images = [] \n",
    "\n",
    "    models = {\n",
    "        'SVM': SVC(),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "    }\n",
    "\n",
    "    # Cross-validation for each model\n",
    "    for model_name, model in models.items():\n",
    "        print(f'Training {model_name} with 5-Fold Cross Validation...\\n')\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            \n",
    "            # Split data into train/validation for this fold\n",
    "            X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "            # Fit the model on the current fold\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Validate on the validation set\n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            val_acc = round(accuracy_score(y_val_fold, y_val_pred), 4)\n",
    "\n",
    "            # Test on the test set\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            test_acc = round(accuracy_score(y_test, y_test_pred), 4)\n",
    "\n",
    "            # Precision, Recall, F1-Score \n",
    "            precision = precision_score(y_test, y_test_pred, average=None, labels=layer_numbers, zero_division=0)\n",
    "            recall = recall_score(y_test, y_test_pred, average=None, labels=layer_numbers)\n",
    "            f1 = f1_score(y_test, y_test_pred, average=None, labels=layer_numbers)\n",
    "\n",
    "            fold_results_list.append({\n",
    "                'Model': model_name,\n",
    "                'Fold': fold + 1,\n",
    "                'Validation Accuracy': val_acc,\n",
    "                'Test Accuracy': test_acc,\n",
    "                'Precision': [round(p, 2) for p in precision],\n",
    "                'Recall': [round(r, 2) for r in recall],\n",
    "                'F1-Score': [round(f, 2) for f in f1]\n",
    "            })\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        sns.set(font_scale=2.0)\n",
    "\n",
    "        heatmap = sns.heatmap(conf_matrix, annot=True, cmap=color, fmt='d', cbar=False,\n",
    "                              xticklabels=layer_labels, yticklabels=layer_labels, annot_kws={\"size\": 36})\n",
    "\n",
    "        plt.title(model_name, size=48)\n",
    "        plt.xlabel('Predicted', size=24)\n",
    "        plt.ylabel('True', size=24)\n",
    "\n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        plt.close()\n",
    "        buf.seek(0)\n",
    "        images.append(buf)\n",
    "\n",
    "    # Write report in CSV file\n",
    "    fold_results_df = pd.DataFrame(fold_results_list)\n",
    "    fold_results_df.to_csv(output_file_path_for_table, index=False)\n",
    "\n",
    "    # Combine and save images\n",
    "    combined_image = combine_images(images)\n",
    "    combined_image.save(output_file_path_for_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRlrtSni006G",
    "outputId": "ca4a08a8-8c42-4fc1-cbaa-adc6749fd0c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM with 5-Fold Cross Validation...\n",
      "\n",
      "Training KNN with 5-Fold Cross Validation...\n",
      "\n",
      "Training DecisionTree with 5-Fold Cross Validation...\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\Users\\chw10\\2023BNEM\\AI\\result\\RGB_DIST'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m machineLearning_print_val_test([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB_dist\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m machineLearning_print_val_test([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYIQ_dist\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[25], line 114\u001b[0m, in \u001b[0;36mmachineLearning_print_val_test\u001b[1;34m(feature, X, y, material, color, labels)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Write report in CSV file\u001b[39;00m\n\u001b[0;32m    113\u001b[0m fold_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(fold_results_list)\n\u001b[1;32m--> 114\u001b[0m fold_results_df\u001b[38;5;241m.\u001b[39mto_csv(output_file_path_for_table, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Combine and save images\u001b[39;00m\n\u001b[0;32m    117\u001b[0m combined_image \u001b[38;5;241m=\u001b[39m combine_images(images)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\Users\\chw10\\2023BNEM\\AI\\result\\RGB_DIST'"
     ]
    }
   ],
   "source": [
    "machineLearning_print_val_test(['RGB_dist'])\n",
    "machineLearning_print_val_test(['YIQ_dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
